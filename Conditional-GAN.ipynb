{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca4c408",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchvision\n",
    "import torchvision.datasets as dataset\n",
    "import torchvision.transforms as transform\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d0c598",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the dataset\n",
    "\n",
    "transforms = transform.Compose(\n",
    "    [transform.ToTensor(),\n",
    "    transform.Normalize((0.5,), (0.5,))]\n",
    "    \n",
    ")\n",
    "data = dataset.FashionMNIST('./', train=True, download=True, transform=transforms)\n",
    "train_data = DataLoader(data, batch_size=64, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c17ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "d, l = next(iter(train_data))\n",
    "d.shape, l.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d8c6424",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, img_channel, random_noise_channel, num_class):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.device = \"cuda\"\n",
    "        \n",
    "        self.emb_vector = nn.Embedding(num_embeddings= num_class, embedding_dim=num_class)\n",
    "        self.input_dim = random_noise_channel + num_class\n",
    "        \n",
    "        self.g_theta = nn.Sequential(\n",
    "            nn.ConvTranspose2d(self.input_dim, 512, 7, 1, 0),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.LeakyReLU(),\n",
    "            \n",
    "            nn.ConvTranspose2d(512, 256, 4, 2, 1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(),\n",
    "            \n",
    "            nn.ConvTranspose2d(256, 64, 4, 2, 1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(),\n",
    "            \n",
    "            # channel reduction\n",
    "            nn.ConvTranspose2d(64, img_channel, 3, 1, 1),\n",
    "            nn.Tanh() # output: [-1, 1]\n",
    "            \n",
    "        )\n",
    "        \n",
    "    def forward(self, x, label):\n",
    "        embeddings = self.emb_vector(label)\n",
    "        g_input = torch.concat([x, embeddings], dim=1).view(x.shape[0], 160, 1, 1)\n",
    "        \n",
    "        return self.g_theta(g_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a72544",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, num_class):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.emb_vector = nn.Embedding(num_embeddings= num_class, embedding_dim=num_class)\n",
    "        self.D_w = nn.Sequential(\n",
    "            nn.Conv2d(1 + num_class, 64, 4, 2, 1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(),\n",
    "            \n",
    "            nn.Conv2d(64, 128, 4, 2, 1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(),\n",
    "            \n",
    "            nn.Flatten(),\n",
    "            nn.Linear(128*7*7, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x, label):\n",
    "        embeddings = self.emb_vector(label) # (B, 10)\n",
    "        \n",
    "        embeddings = embeddings.unsqueeze(2).unsqueeze(3) # (B, 10, 1, 1)\n",
    "        \n",
    "        embeddings = embeddings.expand(-1, -1, x.size(2), x.size(3)) # (B, 10, 28, 28)\n",
    "        \n",
    "        d_input = torch.cat([x, embeddings], dim=1) # (B, 11, 28, 28)\n",
    "        \n",
    "        return self.D_w(d_input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6473dfda",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.set_device(1)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device\n",
    "print(torch.cuda.get_device_name(torch.cuda.current_device()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d52890bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_noise_dim = 150\n",
    "image_channel = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be4e97bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = Generator(img_channel= image_channel, random_noise_channel=random_noise_dim, \n",
    "                    num_class=10).to(device)\n",
    "\n",
    "discriminator = Discriminator(10).to(device)\n",
    "\n",
    "generator, discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fdba47c",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_g = optim.Adam(generator.parameters(), lr=2e-4, betas=(0.5, 0.999))\n",
    "optimizer_d = optim.Adam(discriminator.parameters(), lr=2e-4, betas=(0.5, 0.999))\n",
    "\n",
    "criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a6213d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def show_generated_images(epoch, generator, fixed_noise, labels):\n",
    "    generator.eval()\n",
    "    with torch.no_grad():\n",
    "        fake_imgs = generator(fixed_noise, labels)\n",
    "        fake_imgs = fake_imgs * 0.5 + 0.5  # De-normalize\n",
    "\n",
    "    grid = torchvision.utils.make_grid(fake_imgs, nrow=8)\n",
    "    plt.figure(figsize=(8,8))\n",
    "    plt.imshow(grid.permute(1, 2, 0).cpu().numpy())\n",
    "    plt.title(f'Generated Images at Epoch {epoch}')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    generator.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd85bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Discriminator\n",
    "fixed_random_samples = torch.randn(64, random_noise_dim).to(device)\n",
    "fixed_labels = torch.randint(6, 7, (64, )).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f51e6571",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for idx, (data, label) in enumerate(train_data):\n",
    "        batch_size = data.shape[0]\n",
    "        \n",
    "        # create labels - discriminator\n",
    "        ones = torch.ones(batch_size, 1).to(device) # for samples from dataset\n",
    "        zeros = torch.zeros(batch_size, 1).to(device) # for samples from generator\n",
    "        \n",
    "        # Train Discriminator\n",
    "        z = torch.randn(batch_size, random_noise_dim).to(device)\n",
    "        fake_labels = torch.randint(0, 10, (batch_size, )).to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            generated_images = generator(z, fake_labels)\n",
    "        \n",
    "        output_d = discriminator(data.to(device), label.to(device))\n",
    "        loss_d = criterion(output_d, ones)\n",
    "        \n",
    "        output_g = discriminator(generated_images.detach().to(device), fake_labels)\n",
    "        loss_g = criterion(output_g, zeros)\n",
    "        \n",
    "        disc_loss = loss_d + loss_g\n",
    "        \n",
    "        optimizer_d.zero_grad()\n",
    "        disc_loss.backward()\n",
    "        optimizer_d.step()\n",
    "        \n",
    "        # Training the generator\n",
    "        for _ in range(5):\n",
    "            z = torch.randn(batch_size, random_noise_dim).to(device)\n",
    "            fake_labels = torch.randint(0, 10, (batch_size, )).to(device)\n",
    "            \n",
    "            generated_images = generator(z, fake_labels)\n",
    "            \n",
    "            output_g = discriminator(generated_images.to(device), fake_labels)\n",
    "            g_loss = criterion(output_g, ones) # tricking the discriminator\n",
    "            \n",
    "            optimizer_g.zero_grad()\n",
    "            g_loss.backward()\n",
    "            optimizer_g.step()\n",
    "        \n",
    "    \n",
    "    if (epoch+1) % 10 == 0:\n",
    "            print(f\"Epoch [{epoch+1}/{epochs}], D_loss: {disc_loss.item():.4f}, G_loss: {g_loss.item():.4f}\")\n",
    "            show_generated_images(epoch+1, generator, fixed_random_samples, fixed_labels)\n",
    "            torch.cuda.empty_cache()\n",
    "    else:\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}], D_loss: {disc_loss.item():.4f}, G_loss: {g_loss.item():.4f}\")\n",
    "         \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RNN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
